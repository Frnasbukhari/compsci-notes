# Intelligent Interactive Systems, Responsible AI, and AI Ethics

[Listen to the AI-generated overview podcast on this lecture!](https://notebooklm.google.com/notebook/74281342-5b37-48ec-a545-770e861b4dd3/audio)


---

## 1. Intelligent Interactive Systems
<img src="https://platform.polygon.com/wp-content/uploads/sites/2/2024/08/the-wild-robot-gallery5.jpg?quality=90&strip=all&crop=0,3.4613147178592,100,93.077370564282" alt="IIS" width="400">

### Definition and Scope
- **Intelligent Interactive Systems** are software or technological systems that:
  - **Perceive** their environment and/or user inputs.
  - **Act** (often in real time) in ways that are adaptive or goal-directed.
  - **Engage in cognitive processing** to understand and potentially anticipate user intentions.
- They are **not** meant to be Artificial General Intelligence (AGI); rather, they focus on specific cooperative or interactive tasks.

### Key Elements of Interaction
<img src="https://media.istockphoto.com/id/1371325601/photo/ai-cyborg-robot-whispering-secret-or-interesting-gossip.jpg?s=612x612&w=0&k=20&c=jWnFCJudT7Df-DeiDKbdVUgBFiJtQY5ws5e8RHB1Jck=" alt="Interaction" width="400">

- **Interaction**: Involves a genuine exchange or “discourse” with the user.  
  - The system should understand the user’s goals, respond appropriately, and adapt over time.
  - This includes **cooperation** or **collaboration** with human users.
  - Interaction can occur on multiple timescales:
    1. **Immediate perception-action** (e.g., reacting to a user’s click or voice command).
    2. **Conversational** exchanges (text or speech-based).
    3. **Higher-level decision-making** (longer-term goals and preferences).
- **Co-adaptive Setting**: Estimating a user’s intentions is dynamic—both user and system may adapt in response to each other’s actions (e.g., a penalty taker vs. a goalie in sports).

### Intelligence and Rationality
<img src="https://media.licdn.com/dms/image/v2/C5112AQHWlTNC3-NHdw/article-cover_image-shrink_600_2000/article-cover_image-shrink_600_2000/0/1579769922283?e=2147483647&v=beta&t=zX-iws3VuDq0e1LaThjf2ZNJ9gfhY6aO_dlF7zWBXUk" alt="psychology" width="400">

- **Rational choices**: Intelligence here means making the best possible choice given data and an objective.
- Systems rely on **models of human psychology** that:
  - Have **explanatory power** (they explain user behavior).
  - Have **predictive power** (they anticipate future actions or preferences).
  - Are **consistent across contexts**.
  - Align with other relevant scientific models.

---

## 2. Responsible AI

This section explores modern AI developments, particularly **Generative AI** and **Large Language Models (LLMs)**, while highlighting major challenges like bias and misinformation.

### Generative AI and Large Language Models
<img src="https://syndelltech.com/wp-content/uploads/2024/05/Large-Language-ModelsLLM-vs-Generative-AI.webp" alt="GenAI" width="400">

- **Generative AI** can produce new content—text, images, audio, video—by learning patterns from large datasets.
- **Large Language Models (LLMs)** (e.g., GPT-style models) predict the next word in a sequence, but do not “understand” meaning as humans do.  
  - They are trained on vast corpora of text, learning statistical relationships between words.

### Foundations of Neural Networks
1. **Perceptrons**
   - Early neuron-inspired models that compute weighted sums of inputs.  
   - Limited (e.g., cannot learn XOR).

<img src="https://miro.medium.com/v2/resize:fit:1290/0*LJBO8UbtzK_SKMog" alt="Perceptrons" width="400">

2. **Multilayer Perceptrons**
   - Add hidden layers, use backpropagation to train on labeled data.  
   - The backbone of deeper architectures.

<img src="https://miro.medium.com/v2/resize:fit:1400/1*MF1q2Q3fbpYlXX8fZUiwpA.png" alt="Multilayer Perceptrons" width="400">

3. **Deep Learning Revolution** (post-2010)
   - Driven by large datasets, more compute power (GPUs), and specialized architectures like **Convolutional Neural Networks (CNNs)** for images.       
<img src="https://miro.medium.com/v2/resize:fit:1400/1*7_BCJFzekmPXmJQVRdDgwg.png" alt="CNN" width="400">

---

### Word Embeddings
<img src="https://www.cs.cmu.edu/~dst/WordEmbeddingDemo/figures/fig5.png" alt="Word2Vec" width="400">

- **One-hot encoding**: Simple but sparse representation (each word as a huge vector mostly full of zeros).
- **Word2Vec** (Mikolov, 2013):  
  - Learns dense embeddings where similar words are close in vector space.  
  - Methods include **Continuous Bag of Words (CBOW)** and **Skip-gram**.

### RNNs and Transformers
- **Recurrent Neural Networks (RNNs)**  
  - Handle sequences by updating internal states word by word.  
  - Often suffer from vanishing gradients, making deep training harder.
- **Transformers**  
  - Rely on **attention mechanisms**, processing sequences in parallel rather than step by step.  
  - Enable state-of-the-art NLP performance, powering modern LLMs.

---


### Major Challenges in LLMs
<img src="https://therecursive.com/cdn-cgi/image/format=auto/wp-content/uploads/2023/08/USE-THIS-FOR-SOCIAL-MEDIA-1200x628-2023-08-24T164445.844-900x471.png" alt="LLMs" width="400">

1. **Bias**  
   - Data reflect societal biases (sexism, racism, etc.).  
   - LLMs can inadvertently perpetuate or amplify these biases.
2. **Hallucinations**  
   - LLMs can “make up” plausible but false information.  
   - They are not inherently “grounded” in external facts.
3. **Adversarial Attacks**  
   - “Jailbreaking” LLMs through malicious prompts or hacks to bypass safeguards.
4. **Data Privacy & Security**  
   - Large datasets may contain sensitive user information.

### Mitigation and Improvements
<img src="https://static.independent.co.uk/s3fs-public/thumbnails/image/2017/04/13/13/123123312.jpg?quality=75&width=1200&auto=webp" alt="Mitigation" width="400">

- **Retrieval Assisted Generation (RAG)**  
  - Combines LLMs with document retrieval to ensure generated text aligns with verified information.
- **Reinforcement Learning from Human Feedback**  
  - Adjust model outputs based on evaluative feedback from humans.
- **Guard Rails & Prompt Engineering**  
  - Carefully design prompts to reduce inappropriate outputs.  
  - Add policy layers and usage guidelines.
- **Transparency & Auditing**  
  - “Transparency by design” fosters accountability.  
  - **Independent audits** can help uncover biases and vulnerabilities.
- **Technical Innovations**  
  - Watermarking generated content.  
  - New approaches to verifying or constraining outputs.

---

## 3. Ethics of AI
<img src="https://lh7-us.googleusercontent.com/AIqaMe8A4KwlHlmWXkfenfega_g4KUy19NyeL6EsioydBXBPKf-R1jgJqBQTqQ_l12jNUSjyMrykBMcbLlAjxg-Ko0ex6ucLJr1AF-wLRV2vKi1lZ4brrBvXjiUbZwvdw5AHrbWLoOOKc5yWaAVtsX4" alt="Lawyer robot" width="400">

While responsible AI focuses on practical measures (like bias reduction and technical fixes), **AI Ethics** tackles broader social, moral, and systemic questions.

### Current AI Ethics Guidelines
<img src="https://allai.nl/wp-content/uploads/2020/07/Screenshot-2020-07-14-at-16.51.39.png" alt="AI Guidelines" width="400">

- A **proliferation** of guidelines has emerged from corporations, governments, and NGOs.
- Common themes:
  - **Privacy, fairness, accountability, transparency, safety, cybersecurity,** and serving the **common good**.
- **Major critique**  
  - These guidelines often lack enforcement or legal backing.  
  - They can be used to forestall tighter regulation or provide public relations benefits without ensuring real change.

### Recurring Gaps
1. **Lack of Implementation**  
   - Little research on how to translate ethical goals into everyday practice in AI labs and companies.
2. **Justice vs. Care Ethics**  
   - Most guidelines emphasize “male-oriented” justice ethics (rules, accountability, metrics).  
   - They overlook “care ethics” that focus on nurture, welfare, social responsibility, or ecological concerns.
3. **Omissions**  
   - **Political abuse of AI** (bots, fake news, surveillance).  
   - **Diversity** in the AI community (both in developers and impacted groups).  
   - **Ecological and hidden social costs** (lithium mining, e-waste, low-wage “clickworkers”).  
   - **Public-private partnerships** and industry-driven research agendas.

### Business vs. Ethics
- **Profit motives** and the international “AI race” frequently overshadow ethical considerations.
- Fear of “falling behind” can diminish willingness to impose ethical constraints.

---

### Effectiveness and the Need for Change
<img src="https://futuristspeaker.com/wp-content/uploads/2024/08/futurist-thomas-frey-the-path-forward.jpg" alt="Effectiveness" width="400">

- Studies show **weak influence** of guidelines on the day-to-day decisions of AI practitioners.
- **System Theory** perspective  
  - Different societal systems (business, research, ethics) operate under separate logics.  
  - Ethics guidelines have limited power to modify entrenched commercial or competitive incentives.
- Many ethical goals remain **underachieved**, for instance:
  - Privacy is still threatened by large-scale data collection.  
  - Gender diversity in AI remains low.  
  - Autonomy and social cohesion are challenged by automated propaganda and algorithmic control.

### A Path Forward
1. **Microethics**  
   - Ethics must engage with the actual technical details—how data is gathered, curated, processed, and how code is designed.
2. **Virtue Ethics**  
   - Augment deontological (rule-based) approaches with a focus on moral character, virtues (honesty, empathy, care), and situation-sensitive judgment.
3. **Legal & Structural Support**  
   - Stronger regulatory frameworks and institutions for auditing and complaint resolution.
   - **Education**: Incorporate ethics of technology, media, and information into broader curricula.


By synthesizing insights from Intelligent Interactive Systems, Responsible AI practices, and AI ethics research, these notes highlight both the **enormous potential** of AI for human collaboration and the **significant responsibility** developers, organizations, and policymakers share in shaping the technology’s future.
