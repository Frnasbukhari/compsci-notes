# i) Evolutionary Algorithms
<img src="https://cdn.botpenguin.com/assets/website/Evolutionary_Computation_01b6431b60.webp" alt="EA" width="400">

## 1. Evolution in Nature

**Definition:** Evolution refers to the change in the inherited characteristics of biological populations over successive generations.

Key concepts:
- **Heritable Characteristics:** Traits passed from one generation to the next via DNA (e.g., eye color).
- **Genetic Variation:** The changes responsible for diversity within a species, driven by:
  - **Mutations:** Random changes in DNA.
  - **Crossover:** Genetic recombination through reproduction.
  - **Migration:** Movement of genes between populations.
- **Natural Selection:** The principle of "survival of the fittest," where beneficial traits become more common over time.

### What Evolution Taught Us

- Living organisms are modified versions of their ancestors.
- Evolution is guided by natural selection.


#### **Question:** How does this relate to optimization?
> **Fitness** in optimization corresponds to how well a solution performs.    
> **Individuals of a species** correspond to candidate solutions in an algorithm.

---

## 2. What are Evolutionary Algorithms?

**Definition:** Evolutionary algorithms (EAs) are metaheuristic optimization techniques inspired by natural evolution. Examples include:
- **Genetic Algorithms (GAs)**
- **Evolutionary Programming (EP)**
- **Evolution Strategies (ES)**
- **Differential Evolution (DE)**

### Characteristics of Evolutionary Algorithms
- **Population-based approach:** They are a stochastic local search optimization problem, where we maintain and evolve a group of candidate solutions.
- **Use randomness:** Introduce stochastic elements to avoid local optima.

---

## 3. Generic Evolutionary Algorithm

```
X0 := generate initial *population* of solutions
termination_flag := false
t := 0

Evaluate fitness of each individual in X0

while (termination_flag != true):
    Selection: Choose parents based on fitness
    Variation: Apply mutation and crossover to create new individuals
    Fitness calculation: Evaluate the fitness of offspring
    Reproduction: Replace less-fit individuals with offspring
    t := t + 1

    If termination criteria met: termination_flag := true

Output best solution found
```

---

## 4. Building Blocks of Evolutionary Algorithms

To apply an EA to a problem, the following are needed:
- **Representation:** How solutions are encoded.
- **Fitness Function:** Evaluates the quality of solutions.
- **Variation Operators:** Mutation and crossover to explore solutions.
- **Selection and Reproduction:** Guides the algorithm towards better solutions.

#### **Exploration vs. Exploitation**
- **Exploration:** Searching a wide range of possible solutions (variation operators).
- **Exploitation:** Refining known good solutions (selection and reproduction).

---

## 5. Representation
<img src="../../images/representation.png" alt="Representation" width="400">

**Definition**: Representation refers to encoding solutions in a way that allows the algorithm to manipulate and evaluate them.

- **Phenotype:** The actual solution (e.g., a number or a path in a graph).
- **Genotype:** The encoded form used by the algorithm (e.g., binary string).
- **Encoding Function:** Maps a phenotype to a genotype.
- **Decoding Function:** Maps a genotype back to a phenotype.

### 5.1 Types of Representations
- **Binary Representation** (traditionally used in genetic algorithms but inefficient):
  - Solutions encoded as bit strings.
  - Example: `{0,1,1,0,1,0}`
- **Real Number Representation:**
  - Used for continuous variables.
  - Example: `{3.5, -2.7, 1.8}`
- **Also, Permutation Representation, Random Key Representation and Problem-Specific Representation**

---

### 5.2 Example of Binary Representation:
A solution space mapped to binary (bits string):
```
Solution (x): -5    -3    0     3    5
Binary:        0000  0100 1000 1100 1111
```

### 5.3 Decoding Function Example:
Assume `x= {x1, x2, x3}` and `x ∈ [-5, 5]`. Use a bit string of length L= 12, therefore L/3 = 4 bits,  divided into three segments:
```
Binary:   1101 0001 1111
Segments: 13   1    15
Decoded:  3.667  -4.333  5
```

---

## 6. Variation Operators for Binary Genetic Algorithms

### 6.1 Mutation
- **Definition:** Randomly flips bits with a small probability `p_m` (mutation rate).
- The standard mutation rate `p_m = 1/L` but can be `p_m ∈ [1/L , 1/2]`
- **Example:**
  - Parent: `00101011`
  - After mutation: `01101001`
- With a small mutation rate, the effect is like a minor perturbation, similar to local search.  
- With a higher mutation rate, it can introduce more randomness, potentially leading to greater exploration.

<img src="https://editor.analyticsvidhya.com/uploads/550041623128158975.png" alt="Mutation" width="400">

---

### 6.2 Crossover  
- **Definition:** Combines genetic material from two parent solutions to create offspring.  
- **Types:**  
  - **One-Point Crossover:** A single crossover point is selected, and genes are swapped after this point.  
  - **N-Point Crossover:** Multiple crossover points are used, alternating segments between parents.  
  - **Uniform Crossover:** Each gene is randomly inherited from either parent with equal probability.  

<img src="https://www.tutorialspoint.com/genetic_algorithms/images/one_point_crossover.jpg" alt="Crossover" width="400">

#### Crossover Example  
```
One-Point Crossover "After the third gene":
Parent 1: 101|011
Parent 2: 110|100
Child 1:  101|100
Child 2:  110|011
```

---

## 7. Pros and Cons of Binary Genetic Algorithms (GAs)

### 7.1 Advantages of Binary Coding
- **Implicit Parallelism:**
  - Binary encoding enables the efficient exploration of multiple schemata (templates describing patterns in bit strings) simultaneously.
  - A chromosome of length \(L\) contains \(3^L\) schemata, leading to an extensive search space.
  - Example:
    - Chromosome 1: `10110110`
    - Chromosome 2: `00100100`
    - Schema 1: `*0**01*0`
    - Schema 2: `****01**`
  - By evaluating and selecting fitter schemata, a GA can optimize efficiently.

### 7.2 Disadvantages of Binary Coding

#### **Hamming Cliff Problem**
- Mutation in binary encoding can cause large or small jumps in phenotype values.
- Example:
  - **Genotypes (Binary Representation):** `000`, `001`, `010`, `011`, `100`, `101`, `110`, `111`
  - **Corresponding Phenotypes:** `0`, `1`, `2`, `3`, `4`, `5`, `6`, `7`
- Problem: A one-bit mutation may result in a large jump (e.g., `011 → 100`, which is a jump from `3` to `4`).

##### **Solution: Gray Encoding**
- Gray encoding ensures small changes in genotype lead to small phenotype changes.
- Example:
  - **Binary Encoding:** `000`, `001`, `010`, `011`, `100`, `101`, `110`, `111`
  - **Gray Encoding:** `000`, `001`, `011`, `010`, `110`, `111`, `101`, `100`
- Uses XOR operation for conversion:
  - \( b_i = a_i \) if \( i = 1 \)
  - \( b_i = a_{i-1} \oplus a_i \) if \( i > 1 \)

#### **Redundancy Issue in Discrete Search Spaces**
- If the number of valid solutions is not a power of two, some binary strings will be redundant.
- Example:
  - Consider a set of solutions \( A = \{0, 2, 3\} \) with \(|A| = 3\).
  - If we use 2-bit encoding:
    - `00 → 0`
    - `01 → 1` (invalid)
    - `10 → 2`
    - `11 → 3`
  - The mapping is not efficient due to redundant strings (`01`).

#### **Precision Issue in Continuous Search Spaces**
- Encoding a continuous number requires a finite-length binary string, leading to precision loss.
- Example:
  - \( x \in [-5, 5] \) encoded as a 12-bit binary string.
  - The precision depends on \( L \), making large-dimensional problems challenging.

---

## 8. Real-Valued Vector Representation

### 9.1 Why Use Real-Valued Encoding?
- More natural representation for continuous optimization problems.
- Avoids issues like redundancy and precision loss.
- No distinction between genotype and phenotype; the chromosome is simply a vector of real numbers.
- Used in **Evolution Strategies (ES), Evolutionary Programming (EP), and Differential Evolution (DE).**

#### **Advantages:**
- No encoding/decoding overhead.
- Better numerical precision.
- Easily scalable for high-dimensional problems.

### 9.2 Representation:
Each solution is represented as:
\[ x = [x_1, x_2, \dots, x_n] \in \mathbb{R}^n \]

Each gene corresponds to a variable in the optimization problem.

---

## 10. Variation Operators for Real-Valued Encoding

### 10.1 Mutation
Randomly selects a parent with probability \( p_m \) and modifies a gene.

#### **Types of Mutation:**
1. **Uniform Mutation**:
   - A gene is replaced with a random value within its allowed range.
   - \( x_i \leftarrow U(u_i, v_i) \) where \( U \) is uniform distribution.

2. **Gaussian Mutation**:
   - A gene is perturbed by adding Gaussian noise.
   - \[ x_i' = \min(\max(N(x_i, \sigma_i), u_i), v_i) \]
   - \( \sigma_i \) is often set relative to the search space size (e.g., \( \sigma_i = \frac{1}{10} (v_i - u_i) \)).

3. **Non-Uniform Mutation**:
   - Mutation strength decreases over generations.
   - Formula:
     \[
     x_i' = \begin{cases}
     x_i + \Delta(t, v_i - x_i) & \text{if } \tau \geq 0.5 \\
     x_i - \Delta(t, x_i - u_i) & \text{if } \tau < 0.5
     \end{cases}
     \]
   - \( \Delta(t, y) = y (1 - r^{(1 - \frac{t}{g_m})^b}) \)


### 10.2 Crossover
Combines genetic material from two parents to create offspring.

#### **Types of Crossover:**

1. **Flat Crossover**:
   - Offspring genes are randomly selected within the range of parent values.
   - \( h_i \in [x_i^{(1)}, x_i^{(2)}] \)

2. **Simple Crossover**:
   - Selects a random crossover point and swaps genes beyond that point.
   - Example:
     - Parent 1: `[1.5, 2.3, 3.8, 4.0]`
     - Parent 2: `[1.2, 3.1, 2.9, 5.2]`
     - Offspring 1: `[1.5, 2.3, 2.9, 5.2]`
     - Offspring 2: `[1.2, 3.1, 3.8, 4.0]`

3. **Whole Arithmetic Crossover**:
   - Uses a weighted average:
     \[ h_i^{(1)} = \alpha x_i^{(1)} + (1 - \alpha) x_i^{(2)} \]
     \[ h_i^{(2)} = \alpha x_i^{(2)} + (1 - \alpha) x_i^{(1)} \]
   - \( \alpha \) is a random value between 0 and 1.

4. **BLX-\(\alpha\) Crossover**:
   - Offspring gene is sampled from a broader range than parents.
   - \[ h_i \in [h_{\min} - I \cdot \alpha, h_{\max} + I \cdot \alpha] \]
   - \( h_{\min} \) and \( h_{\max} \) are min and max values among parents.

---

## 11. Selection

### 11.1 Generic Evolutionary Algorithm

```
X0 := generate initial population of solutions
terminationflag := false
t := 0

Evaluate the fitness of each individual in X0.

while (terminationflag != true):
    Selection: Choose parents based on fitness.
    Variation: Apply mutation and crossover.
    Fitness calculation: Evaluate new individuals.
    Reproduction: Form new population by replacing least-fit individuals.
    t := t + 1
    If termination criteria met: terminationflag := true

Output best solution found
```

### 11.2 Selection Process
- **Not a search operator** but heavily influences search performance.
- **Precedes variation operators**: selects individuals for breeding.
- **Key Idea:**
  - Favors better solutions (higher fitness values).
  - Still allows selection of weaker solutions to maintain diversity.

#### **Why Select Inferior Solutions?**
- Prevents premature convergence.
- Avoids getting stuck in local optima.

### 11.3 Selection Schemes
1. **Fitness Proportional Selection (Roulette Wheel Selection)**
2. **Ranking Selection**
3. **Truncation Selection**
4. **Tournament Selection**
5. **(μ+λ) and (μ,λ) Selection**

---

### 11.4 Fitness Proportional Selection
- **Definition:** Each individual is selected with probability:
  \[
p_i = \frac{f_i}{\sum_{j=1}^{M} f_j}
  \]
  where \( f_i \) is the fitness value of individual \( i \) and \( M \) is the population size.
- **Key Properties:**
  - Higher fitness → Higher probability of selection.
  - Allows weaker individuals to be chosen occasionally.

#### **Scaling in Fitness Proportional Selection**
- **Problem:**
  - Early generations: "Super individuals" dominate → Premature convergence.
  - Later generations: Little fitness difference → Slow convergence.
- **Solution:** Apply **linear scaling**:
  \[
  f'_i = a + b f_i
  \]
  - Typically, \( a = \max(f) \), \( b = \frac{\min(f)}{M} < 1 \).

---

### 11.5 Ranking Selection
- Sort population from best to worst based on fitness.
- Selection probability \( p(γ) \) is assigned based on rank \( γ \):
  - **Linear Ranking:**
    \[
    p(γ) = \frac{α + (β - α)γ}{M - 1}
    \]
  - **Other Methods:** Exponential, Power, Geometric ranking.

---

### 11.6 Truncation Selection
- **Steps:**
  1. Rank individuals by fitness.
  2. Select top \( k \)% for reproduction (e.g., top 50% or 30%).
- **Characteristics:**
  - Deterministic selection (no randomness involved).
  - Commonly used in **Evolution Strategies (ES)**.

---

### 11.7 Tournament Selection
- **Steps:**
  1. Randomly select \( k \) individuals from population.
  2. Choose the fittest individual from the subset.
  3. Repeat until enough offspring are selected.
- **Common Variants:**
  - **Binary Tournament (\( k=2 \))** is the most popular.
  - Higher \( k \) → Higher selection pressure.

---

### 11.7 (μ+λ) and (μ,λ) Selection
- Used in **Evolution Strategies**.

#### **(μ+λ) Selection:**
- Parent population size: \( μ \).
- Generate \( λ \) offspring.
- Next population: Select top \( μ \) from **both** parents and offspring.

#### **(μ,λ) Selection:**
- Parent population size: \( μ \).
- Generate \( λ \) offspring.
- Next population: Select top \( μ \) from **only** offspring.
- Requires \( λ > μ \) to maintain diversity.

---

### 11.8 Selection Pressure
**Selection Pressure:** Degree to which selection favors better individuals.

#### **Effects:**
- **High selection pressure:** Faster convergence, but risks premature convergence.
- **Low selection pressure:** Slow convergence, but better exploration.

#### **Measurement: Take-over Time (\( τ^* \))**
- Time required for the entire population to be taken over by the best individual.
- **Longer \( τ^* \) → Lower selection pressure.**

| Selection Method | Take-over Time (\( τ^* \)) |
|-----------------|----------------------|
| Fitness Prop. Selection | \( M \ln M / c \) |
| Linear Ranking | \( 2 \ln (M-1) / (β-1) \) |
| Truncation | \( \ln M \) |
| Tournament (size \( k \)) | \( \ln M / \ln k \) |
| (μ+λ) Selection | \( \ln λ / \ln(λ/μ) \) |

---

## 12. Reproduction

### Genetic Algorithm Reproduction Strategies
- **Reproduction controls how the next generation is created.**
- **Types:**
  - **Generational Replacement:** Entire population is replaced.
  - **Steady-State Replacement:** Only a few individuals are replaced at a time.
  - **Elitism:** Top \( N \) individuals always survive to the next generation.
  - **Generational Gap:** Percentage of individuals carried over without modification.
