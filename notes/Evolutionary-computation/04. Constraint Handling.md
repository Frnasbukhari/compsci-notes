# Evolutionary Computation: Constraint Handling in Evolutionary Algorithms

---

## 1. Motivating Examples: Engineering Optimisation Problems

In many engineering design problems, the goal is to optimise certain performance measures (such as cost, weight, or material usage) while satisfying a set of constraints imposed by physical laws, regulations, or quality standards.

### Example 1: Cubic Vessel Design

#### Description
- **Objective:** Find optimal values for the design variables:
  - Length (l)
  - Width (w)
  - Height (h)
  - Thickness (t)
  
  The aim is to **minimize material consumption** (or equivalently, the surface area).

- **Constraints:**
  - **Regulatory Constraints:** Government or corporate rules may dictate permissible shapes or maximum capacities.
  - **Quality Constraints:** For example, the design may require that the maximum deflection does not exceed a given allowable value.

#### Clarification & Explanation
- **Design Variables:**  
  These are the parameters that you can control in the design process. In this case, dimensions such as length, width, height, and thickness are continuous variables.
  
- **Optimisation vs. Constraints:**  
  Although the goal is to reduce material usage, you cannot decrease it without bound because the constraints impose limits (such as minimum structural requirements or regulatory standards).

- **Illustrative Example:**  
  - **Design 1:** l = 100 cm, w = 30 cm, h = 40 cm, t = 1 cm.
  - **Design 2:** l = 500 cm, w = 100 cm, h = 160 cm, t = 2 cm.
  
  Even if both designs are feasible, they will have different performances regarding volume, cost, strength, etc.

---

### Example 2: Spring Design

#### Description
- **Objective:** Minimize the weight of a tension/compression spring.
- **Design Variables:**
  - Wire diameter: $x_1$ (continuous variable, e.g., between 0.05 and 2)
  - Mean coil diameter: $x_2$ (continuous variable, e.g., between 0.25 and 1.3)
  - Number of active coils: $x_3$ (continuous or integer, e.g., between 2 and 15)

- **Constraints:**
  - Minimum deflection requirement.
  - Limits on shear stress.
  - Constraints on surge frequency.
  - Restrictions on diameters.

#### Constrained Optimisation Formulation

The spring design problem is formulated as follows:

**Objective Function:**

$$
\min_{X} \; f(X) = (x_3 + 2) \, x_2 \, x_1^2
$$

**Subject to Constraints:**

1. $\displaystyle g_1(X) = 1 - \frac{x_3^2}{1785 \, x_1^4} \le 0$
2. $\displaystyle g_2(X) = \frac{4x_2^2 - x_1x_2}{12566\,(x_2x_3^1 - x_1^4)} + \frac{1}{5108\, x_1^2} - 1 \le 0$
3. $\displaystyle g_3(X) = 1 - \frac{140.45\, x_1}{x_2^2\, x_3} \le 0$
4. $\displaystyle g_4(X) = \frac{x_2 + x_1}{1.5} - 1 \le 0$

#### Clarification & Explanation
- **Objective Function Insight:**  
  The function $f(X) = (x_3 + 2) \, x_2 \, x_1^2$ combines the design variables to reflect the weight of the spring. The term $(x_3 + 2)$ modulates the impact of the number of coils, while $x_2 \, x_1^2$ relates to geometric and material properties.
  
- **Constraints:**  
  Each constraint enforces a specific performance or safety requirement (e.g., stress limits, deflection limits). For example, $g_1(X)$ might ensure that the spring’s strength does not fall below a critical value.

---

### Engineering Optimisation Problems: General Concepts

- **Design Variables:**  
  - *Continuous:* e.g., dimensions like length, width, thickness.
  - *Integer:* e.g., number of gear teeth.
  - *Discrete:* e.g., selecting a value from a standard set defined by design codes.

- **Design Objective:**  
  This represents the target of the design process (e.g., minimising cost or maximizing profit) and is mathematically formulated as an objective function.

- **Constraints:**  
  They impose limitations due to resources (like budget or material limits) or strict design requirements (such as safety or regulatory standards).

- **Optimisation Software:**  
  Tools such as Matlab Optimisation Toolbox, Matlab Global Optimisation Toolbox, Red Cedar Technology, and Omniquest provide practical solutions for these problems.

---

## 2. Constrained Optimisation

### Definition

A **constrained optimisation problem** is one where the objective is to find the best solution subject to a set of restrictions.

**General Formulation:**

$$
\begin{aligned}
\min_{x} \quad & f(x) \\
\text{subject to} \quad & g_i(x) \le 0, \quad i = 1, \dots, m \\
& h_j(x) = 0, \quad j = 1, \dots, p
\end{aligned}
$$

- **$x$**: An $n$-dimensional vector $(x_1, x_2, \dots, x_n)$.
- **$f(x)$**: The objective function.
- **$g_i(x)$**: Inequality constraints.
- **$h_j(x)$**: Equality constraints.

**Search Spaces:**
- **$S$**: The entire search space.
- **$F \subset S$**: The feasible space where all constraints are met.

> **Note:** The global optimum in $F$ may differ from the global optimum in $S$ if the unconstrained optimum lies outside the feasible region.

### Types of Constraints

- **Linear Constraints:**  
  Easier to handle due to their simplicity.
  
- **Non-linear Constraints:**  
  Often more challenging because they can create a complex feasible region.

---

## 3. Constrained Handling Techniques in EAs

Evolutionary Algorithms (EAs) are well-suited for tackling complex optimisation problems, including those with constraints. Here are several strategies used to handle constraints in EAs:

### 3.1 The Purist Approach (Dead Penalty)

- **Method:**  
  Reject any solution that does not meet all constraints.
- **Drawback:**  
  This approach is very strict and may discard solutions that are nearly feasible and have good objective values, thereby reducing genetic diversity and potentially missing good search directions.

---

### 3.2 Penalty Function Approach

#### Introduction
The penalty function approach converts a constrained optimisation problem into an unconstrained one by adding a penalty term to the objective function. This penalty term increases when a solution violates one or more constraints.

**Modified Objective Function:**

$$
f'(x) = f(x) + \text{Penalty Term}
$$

where the **Penalty Term** is typically:

$$
\sum_{i=1}^{m} r_i \, G_i(x) + \sum_{j=1}^{p} c_j \, H_j(x)
$$

- **$r_i, c_j \in \mathbb{R}^+$:** Penalty coefficients.
- **For Inequality Constraints:**

  $$
  G_i(x) = \max(0, g_i(x))^\beta \quad (\beta \text{ is often 2})
  $$

- **For Equality Constraints:**

  $$
  H_j(x) = \max(0, |h_j(x)|)^\gamma \quad (\gamma \text{ is often 2})
  $$

#### Techniques within the Penalty Function Approach

- **Static Penalties:**
  - **Definition:**  
    Penalty coefficients $r_i$ and $c_j$ are fixed throughout the run.
  - **Advantages:**  
    Simple to implement.
  - **Challenges:**  
    Requires good domain knowledge to set proper values.  
    *Tip:* Equality constraints are often relaxed by allowing a small tolerance $\epsilon$:  
    $$
    h_j(x) \Rightarrow h_j(x) - \epsilon \le 0.
    $$

- **Dynamic Penalties:**
  - **Definition:**  
    Penalty coefficients change with the generation number $t$.
  - **Rationale:**  
    As the algorithm progresses, it is often beneficial to increase the penalty for constraint violation so that the search increasingly focuses on feasible regions.
  - **Common Forms:**
    - **Polynomial:**
      $$
      r(t) = \sum_{k=1}^{N} a_{k-1} \, t^{k-1}, \quad c(t) = \sum_{k=1}^{N} b_{k-1} \, t^{k-1}
      $$
    - **Exponential:**
      $$
      r(t) = e^{a\,t}, \quad c(t) = e^{b\,t}
      $$
    - **Hybrid:**  
      A mix of polynomial and exponential forms.

- **Adaptive and Self-Adaptive Penalties:**
  - **Definition:**  
    The penalty values adjust automatically based on the current state of the search, without requiring a predetermined schedule.

#### Impact on Fitness and Selection

Using the modified objective function $f'(x)$ alters the fitness landscape:
- **Ranking Change:**  
  The penalty term can change the relative ranking of solutions. For instance, if solution $x_1$ has a slightly better $f(x_1)$ than $x_2$ but a much larger constraint violation, then a high penalty coefficient $r$ can result in $f'(x_1) > f'(x_2)$.
- **Selection Pressure:**  
  Since selection in an EA is based on fitness, the penalty term indirectly affects the probability of a solution being chosen as a parent.

---

### 3.3 Repair Approach

- **Method:**  
  Instead of discarding infeasible solutions, the repair approach modifies them (or "repairs" them) to satisfy the constraints.
- **Advantage:**  
  This method preserves potentially useful genetic material that might have been lost with strict rejection.

---

### 3.4 Hybrid Approach

- **Method:**  
  Combine two or more constraint handling techniques (e.g., a mix of penalty functions and repair methods) to exploit the advantages of each.
- **Advantage:**  
  It offers greater flexibility in handling a wide variety of constraints.

---

### Additional Note: Penalty Functions and Fitness Landscape Transformation

Different penalty functions transform the fitness landscape in different ways. A well-chosen penalty function should balance the original objective with the degree of constraint violation. In future lectures, advanced methods like *Stochastic Ranking* will be introduced, which modify the selection process more directly to address these challenges.

---

## Generic Evolutionary Algorithm (EA) Pseudocode

Below is a simplified pseudocode representation of a generic evolutionary algorithm:
```pseudo
Initialize population X0 with candidate solutions.
Set termination flag to false.
Set generation counter t = 0.
Evaluate the fitness of each individual in X0.

While termination flag is false:
  1. Selection: Select parents from population Xt based on their fitness.
  2. Variation: Generate offspring via genetic operators (e.g., crossover, mutation).
  3. Fitness Evaluation: Calculate fitness for new individuals (using f'(x) if penalties are applied).
  4. Reproduction: Form new population Xt+1 by replacing less-fit individuals.
  5. Increment generation counter t.
  6. Check if termination criteria are met (e.g., maximum generations, convergence).

Output the best solution x_best.
```

#### Explanation
- **Selection:**  
  Higher fitness (or lower penalty-adjusted objective value) increases a solution’s chance of being selected.
- **Variation:**  
  Genetic operators explore the search space by introducing new candidate solutions.
- **Fitness Evaluation:**  
  For constrained problems, the fitness evaluation includes penalty terms that penalize constraint violations.
- **Reproduction:**  
  The algorithm replaces lower-quality solutions with better ones, ensuring gradual improvement.

---

## 1. Stochastic Ranking

### Overview

Stochastic Ranking was proposed by Dr. Runarsson and Prof. Xin Yao in 2000 as a rank-based selection scheme for handling constraints. Rather than modifying the fitness function with penalty terms, this method directly adjusts the ranking of individuals in the population. It is self-adaptive, with very few parameters to tune, and has become one of the popular techniques for constraint handling due to its effectiveness and simplicity.

### Why Use Stochastic Ranking?

Traditional penalty functions transform the fitness by adding a term that penalizes constraint violations. However, this indirectly changes the selection probability by altering the ranking. Stochastic Ranking, in contrast, directly addresses the ranking problem:
- **Directly Adjusts Selection:** Instead of modifying fitness values, it changes the order in which solutions are ranked.
- **Balancing Act:** It maintains a balance between the original objective (the fitness function $f(x)$) and the degree of constraint violation $G(x)$.

### The Stochastic Ranking Algorithm

The algorithm essentially performs a bubble-sort-like procedure that iteratively compares and potentially swaps individuals based on both their objective value and their constraint violation. Below is the pseudocode:

```pseudo
Do until no change in ranking:
  For i = 1 to M - 1 do:
    u = U(0, 1) // u is a uniformly distributed random number
    If (G(x_i) = G(x_i+1) = 0) OR (u ≤ P_f) then:
      If f(x_i) > f(x_i+1) then swap(x_i, x_i+1)
      Else: If G(x_i) > G(x_i+1) then swap(x_i, x_i+1)
```


- **Variables:**
  - **M:** Total number of individuals.
  - **$G(x)$:** The sum of constraint violations for a solution $x$.
  - **$P_f$:** A constant (often set between 0.45 and 0.5) representing the probability of using the objective function for comparison.

### The Role of $P_f$

- **$P_f > 0.5$:**  
  Most comparisons use the objective function $f(x)$. This setting can allow many infeasible solutions (i.e., those that violate constraints) to be ranked high.
  
- **$P_f < 0.5$:**  
  Most comparisons focus on $G(x)$, the degree of constraint violation. This means that infeasible solutions are less likely to be favored, but it may also lead to a population with poorer overall fitness.
  
- **In Practice:**  
  $P_f$ is typically set between 0.45 and 0.5. Allowing some infeasible solutions helps the algorithm explore the search space more broadly—these solutions might be close to feasibility and, with slight modifications, can lead to high-quality feasible candidates.

---

## 2. Feasibility Rules

### Overview

Feasibility Rules, introduced by Deb in 2000, offer an alternative approach by changing the selection mechanism directly rather than altering fitness values with penalties. This method uses simple, rule-based comparisons during tournament selection to decide which individuals should be favored.

### The Feasibility Rules

When selecting individuals (often via binary tournament selection), the following rules are applied:
1. **Between Two Feasible Solutions:**  
   The one with the better fitness (lower value in a minimization problem) wins.
2. **Between a Feasible and an Infeasible Solution:**  
   The feasible solution always wins.
3. **Between Two Infeasible Solutions:**  
   The solution with the lower degree of constraint violation $G(x)$ wins.

### Pros and Cons

- **Advantages:**
  - **Parameter-Free:**  
    No extra parameters (such as penalty coefficients) need to be tuned.
  - **Simplicity:**  
    Easy to implement and understand.
  
- **Disadvantages:**
  - **Premature Convergence:**  
    Strictly preferring feasible solutions can sometimes cause the algorithm to converge too early to a local optimum, as diversity may be reduced.  
    *(Discussion point: Can the method be improved to balance exploration and exploitation better?)*

---

## 3. Repair Approach

### Overview

The Repair Approach handles constraints by “repairing” infeasible solutions—altering them so they become feasible—rather than modifying the selection or fitness function. This method can preserve useful genetic material that might otherwise be discarded and help guide infeasible solutions towards the feasible region.

### Basic Idea

- **Two Populations:**  
  - **Evolving Population:** Contains both feasible and infeasible individuals.
  - **Reference Population:** Consists solely of feasible individuals, which can be used as guides.
  
- **Objective:**  
  Convert an infeasible individual $I_s$ into a feasible one $z_i$ using information from a reference feasible individual $I_r$.

### The Repairing Algorithm

The repair process is typically executed as follows:

1. **Select a Reference:**  
   Choose a feasible individual $I_r$ from the reference population.
   
2. **Generate a New Candidate:**  
   Create a candidate solution $z_i$ by taking a linear combination of the infeasible individual $I_s$ and the reference $I_r$:
   $$
   z_i = a_i I_s + (1 - a_i) I_r \quad \text{with } 0 < a_i < 1
   $$
3. **Evaluate:**  
   Compute the fitness $f(z_i)$.
   
4. **Replacement Decision:**  
   - If $f(z_i) \le f(I_r)$, then replace $I_s$ with $z_i$.
   - Otherwise, with a probability $P_r$ (typically a small number, < 0.5), replace $I_s$ with $z_i$.

### Implementation Considerations

- **Initial Reference Individuals:**  
  These can be obtained via preliminary exploration or by incorporating human expertise.
  
- **Selecting $I_r$:**  
  Options include random selection, selection based on fitness, or based on proximity (distance) between $I_s$ and potential references.
  
- **Determining $a_i$:**  
  Can be chosen uniformly at random between 0 and 1 or follow a predetermined sequence.
  
- **Choosing $P_r$:**  
  This probability is typically set to a value less than 0.5 to ensure that only promising repairs are accepted.

### Visual Representation

Imagine the search space divided into feasible and infeasible regions. The repair algorithm “pulls” an infeasible solution from the infeasible region towards a known feasible solution, thereby guiding it into the feasible region.
