# Multi-Objective Optimization

Many real-world problems require balancing several conflicting objectives. For instance, when booking a flight, you may have to choose between:
- **Cost:** A cheaper flight might be less convenient.
- **Comfort:** A more convenient flight might be more expensive.

These trade-offs mean there is no single “best” solution—instead, there is a set of solutions that provide different compromises.

---

## 1. Basic Concepts in Multi-Objective Optimization

### 1.1 Domination

A solution **x(1)** is said to dominate another solution **x(2)** if:
1. **x(1) is no worse than x(2) in all objectives.**
2. **x(1) is strictly better than x(2) in at least one objective.**

> **Example:**  
> Suppose you are comparing two designs for a product based on cost and quality.  
> - **Design A:** Cost = \$100, Quality Score = 80  
> - **Design B:** Cost = \$120, Quality Score = 75  
> Here, Design A is cheaper and has a higher quality score, so it dominates Design B.

### 1.2 Pareto-Optimal Solutions

- **Pareto-optimal solutions** are those that are not dominated by any other solutions in the set.  
- When you consider all solutions in a set \(P\), the subset \(P'\) that includes every solution not dominated by another is called the **Pareto front**.

> **Clarification:**  
> Even if no single solution is best in all objectives, the Pareto front represents the set of “best compromises” available.

- **Algorithmic Note:**  
  Computing the non-dominated set can be done using algorithms with computational complexity of roughly \(O(MN^2)\) (where \(M\) is the number of objectives and \(N\) is the number of solutions).

### 1.3 Pareto Front

The **Pareto front** graphically represents the trade-offs between objectives. Depending on the nature of the objectives (to be minimized or maximized), you can visualize different types of fronts:
- **Min–Min:** Both objectives are to be minimized.
- **Max–Max:** Both objectives are to be maximized.
- **Min–Max / Max–Min:** One objective is minimized while the other is maximized.

> **Example:**  
> Consider an optimization problem where you need to minimize both cost and time. The Pareto front would show solutions where improving cost further would lead to a longer time or vice versa. This curve of trade-off points helps decision-makers choose the solution that best meets their specific needs.

---

## 2. Preference-Based Approaches

### Weighted Sum Method

One common approach to transform a multi-objective problem into a single-objective one is by **constructing a weighted sum**:
\[
F(x) = \sum_{m=1}^{M} w_m \, f_m(x)
\]
- **\(f_m(x)\):** The \(m\)th objective function.
- **\(w_m\):** The weight representing the relative importance of the \(m\)th objective.

> **How It Works:**  
> The decision-maker specifies a weight vector \(w\) that indicates the importance of each objective. The optimization then seeks to minimize (or maximize) the composite function \(F(x)\).

### Challenges with the Weighted Sum Method

- **Choosing Weights:** It is often difficult to determine the correct weights without clear prior knowledge.
- **Non-Uniform Pareto Solutions:** The resulting Pareto-optimal solutions might not be uniformly distributed along the Pareto front.
- **Missing Some Solutions:** This method can sometimes fail to capture solutions in non-convex regions of the objective space.

> **In Practice:**  
> While weighted sums are straightforward, they require careful tuning and might not reveal all viable trade-offs between objectives.

---

## 3. Ideal Multi-Objective Optimization Process

An ideal approach to multi-objective optimization is divided into two steps:

1. **Step 1:** Find a set of Pareto-optimal solutions.
2. **Step 2:** Select one solution from this set based on additional, higher-level criteria (preferences, constraints, or decision-maker inputs).

> **Clarification:**  
> - **Step 1** uses techniques (such as evolutionary algorithms) to explore the solution space and generate a diverse Pareto front.
> - **Step 2** then involves decision-making where further preferences are applied to choose the final solution.

> **Example:**  
> In designing a vehicle, multiple design alternatives (trade-offs between speed, fuel efficiency, and cost) are generated. In the next step, additional criteria like safety standards or brand values help choose the best design.

---

## 4. Goals in Multi-Objective Optimization

There are two primary goals when performing multi-objective optimization:

1. **Convergence:**  
   Ensure that the solutions generated by the algorithm are as close as possible to the true Pareto-optimal front.
2. **Diversity:**  
   Maintain a wide spread of solutions so that the decision-maker can see the full spectrum of trade-offs.

> **Importance:**  
> Convergence ensures optimality while diversity provides multiple alternatives for making informed decisions.

---

## 5. Why Evolutionary Algorithms for MOEAs?

**Evolutionary Algorithms (EAs)** are particularly well-suited for multi-objective optimization because:
- **Population-Based Search:**  
  They work with a whole population of candidate solutions, making it easier to find multiple, diverse trade-offs simultaneously.
- **Niche Preservation:**  
  Techniques like niche-preservation help in maintaining diversity, ensuring that different regions of the Pareto front are explored.

> **Example:**  
> Algorithms such as NSGA-II or SPEA2 use non-dominated sorting and crowding distance measures to both converge towards the Pareto front and maintain a diverse set of solutions.

---

## 6. History of Multi-Objective Evolutionary Algorithms (MOEAs)

The development of MOEAs has evolved over several decades:
- **Early Approaches:**  
  Initially, penalty-based methods were used.
- **VEGA (1984):**  
  One of the first attempts at multi-objective evolutionary optimization.
- **Goldberg’s Suggestion (1989):**  
  Proposed ideas that later influenced many MOEA developments.
- **MOGA, NSGA, NPGA (1993–1995):**  
  These early algorithms set the stage for modern techniques.
- **Elitist MOEAs (1998 – Present):**  
  Methods like SPEA, NSGA-II, PAES, and MOMGA have further refined the approach by incorporating elitism to retain the best solutions.

> **Note:**  
> The timeline reflects a steady progression towards more efficient and robust methods in handling multi-objective problems.

---

## 8. Adapting a Simple Genetic Algorithm for Multi-Objective Problems

To extend a basic Genetic Algorithm (GA) for multi-objective optimization, one key change is required: **modifying the fitness computation.**

### Standard GA Workflow:
1. **Initialization:**  
   Generate an initial population.
2. **Evaluation:**  
   Compute the fitness of each individual.
3. **Reproduction:**  
   Select individuals based on fitness, then apply crossover and mutation.
4. **Iteration:**  
   Repeat the process until a termination condition is met.

### Modification for MOEAs:
- **Fitness Assignment:**  
  Instead of using a single fitness value, assign fitness based on Pareto dominance (for example, through non-dominated sorting).
- **Selection:**  
  Use the rank (which Pareto front a solution belongs to) to guide selection.

> **Clarification:**  
> Although the overall GA structure remains the same, the evaluation step now considers multiple objectives, allowing the algorithm to favor solutions that contribute to a diverse Pareto front.

---

## 9. Identifying the Non-Dominated Set

To identify the Pareto-optimal (non-dominated) set from a given population \(P\), you can use the following steps:

1. **For each solution \(i\) in \(P\):**
   - Compare it against every other solution \(j\) (where \(j \neq i\)).
2. **Determine Dominance:**
   - If any \(j\) dominates \(i\), then \(i\) is not included in the non-dominated set.
   - Otherwise, include \(i\) in the non-dominated set \(P'\).
3. **Complexity:**  
   This procedure has a computational complexity of \(O(MN^2)\) (with \(M\) objectives and \(N\) solutions).

> **Example:**  
> In a population of 50 candidate solutions evaluated on 3 objectives, each solution is compared with the other 49. The solutions that are never dominated form the Pareto front.

---

## 10. Non-Dominated Sorting Algorithms

A common approach in MOEAs is to classify the population into multiple non-dominated fronts:
1. **First Front:**  
   Identify the best non-dominated set (first Pareto front).
2. **Remove the First Front:**  
   Exclude these solutions from the population.
3. **Repeat:**  
   Identify the next non-dominated set from the remaining solutions.
4. **Continue:**  
   Repeat until all solutions are classified into successive fronts.

> **Application:**  
> This sorted ranking can be used in selection processes (e.g., in NSGA-II) to guide reproduction and mutation, giving higher preference to solutions in better (lower-numbered) fronts.

---

## 11. Applications of MOEAs

Multi-Objective Evolutionary Algorithms have been applied in a wide range of fields, including:
- **Spacecraft Trajectory Optimization:**  
  Balancing fuel consumption, travel time, and safety.
- **Engineering Component Design:**  
  Optimizing performance, durability, and cost.
- **Microwave Absorber Design:**  
  Managing efficiency and physical constraints.
- **Ground-Water Monitoring:**  
  Balancing coverage, cost, and environmental impact.
- **Extruder Screw Design:**  
  Optimizing design parameters for efficiency and durability.
- **Airline Scheduling:**  
  Balancing cost, time, and customer satisfaction.
- **VLSI Circuit Design:**  
  Trade-offs between power consumption, speed, and area.
- **Other Applications:**  
  Numerous other complex systems benefit from MOEAs.

---


## 12. Shortcomings of Non-Elitist MOEAs

Non-elitist multi-objective evolutionary algorithms (MOEAs) suffer from the absence of **elite preservation**. In single-objective evolutionary algorithms (SOEAs), maintaining elite individuals is critical for convergence, and the same holds true for MOEAs.

**Key Points:**
- **Elite Preservation Missing:** Without keeping an archive of the best (non-dominated) solutions, high-quality solutions may be lost.
- **Three Essential Tasks:**
  - **Elite Preservation:** Retaining the best solutions discovered.
  - **Progress Towards the Pareto-Optimal Front:** Steering the search toward the best trade-offs.
  - **Maintaining Diversity:** Ensuring a well-spread set of solutions across the objective space.

> **Example:**  
> Consider designing an aircraft where multiple conflicting objectives (fuel efficiency, speed, safety) are optimized. Without an elite archive, some promising designs might get discarded over successive generations, reducing the chance of finding an optimal set of trade-offs.

---

## 13. Elitist MOEAs

Elitist MOEAs address the shortcomings of non-elitist methods by incorporating mechanisms that:
- **Preserve Elite Solutions:** Maintain an archive of non-dominated solutions.
- **Drive Convergence:** Favor non-dominated solutions to progress toward the Pareto front.
- **Ensure Diversity:** Use clustering, niching, or grid-based competition to distribute solutions throughout the objective space.

> **Clarification:**  
> The archive works like a “memory” of the best solutions so far, ensuring they are not lost even as new solutions are generated.

---

## 14. NSGA-II: Non-dominated Sorting Genetic Algorithm II

NSGA-II is a widely used elitist MOEA that effectively balances convergence and diversity.

### Non-Dominated Sorting

For each solution in the population, NSGA-II computes:
- **\( n_i \):** The number of solutions that dominate solution \( i \).
- **\( S_i \):** The set of solutions that are dominated by solution \( i \).

The process ranks solutions into different Pareto fronts:
- Solutions with \( n_i = 0 \) (not dominated by any other) form the first Pareto front.
- Subsequent fronts are determined by removing the current front and repeating the process.

> **Example:**  
> With five solutions, if solution A is not dominated by any others (\( n_A = 0 \)), it is placed in the first front. Solutions dominated by A but not by each other might fall into the second front.

**Complexity:**  
The sorting typically operates with a complexity of \( O(MN^2) \) (with \( M \) objectives and \( N \) solutions).

### Elite Preservation and Crowding Distance

- **Elite Preservation:**  
  NSGA-II retains high-quality solutions by merging the parent and offspring populations and then selecting the best individuals.

- **Crowding Distance:**  
  This metric measures the density of solutions surrounding a given solution. When solutions have the same rank, those in less crowded areas are preferred, ensuring diversity across the Pareto front.

> **Real-World Analogy:**  
> Think of crowding distance like ensuring that in a job interview, candidates are not only selected for their qualifications but also for representing diverse skills and experiences.

**Overall Complexity:**  
While the non-dominated sorting is \( O(MN^2) \), the crowding distance computation is \( O(MN \log N) \).

---

## 15. NSGA-II Simulation Results

Simulation studies of NSGA-II (often using a binary-coded representation) typically demonstrate:
- **Convergence:** A clear trend towards the true Pareto front.
- **Diversity:** A well-distributed set of solutions covering various trade-offs.

> **Observation:**  
> Graphs from simulation results usually show clusters of solutions along the Pareto front, confirming that NSGA-II successfully preserves elite individuals while maintaining diversity.

---

## 16. Strength Pareto EA (SPEA)

SPEA is an elitist MOEA that uses an external archive to store non-dominated solutions.

**Key Features:**
- **External Archive:**  
  Stores the current set of non-dominated solutions separately from the main population.
  
- **Fitness Assignment:**  
  - For external archive members, fitness is based on the number of population solutions they dominate (fewer is better).
  - For population individuals, fitness is the sum of the fitness values of external solutions that dominate them.
  
- **Selection & Recombination:**  
  Tournament selection is performed on the combined set (current population and archive), with recombination applied to generate new offspring.
  
- **Clustering for Diversity:**  
  When the archive exceeds a set limit, clustering techniques help maintain a diverse set of solutions.

> **Practical Example:**  
> In an automotive design problem, SPEA helps in retaining a diverse set of designs that balance factors like cost, performance, and safety, even if some designs slightly underperform in one objective.

---

## 17. Pareto Archived ES (PAES)

PAES is a simpler approach based on a (1+1)-evolution strategy (ES) with an external archive.

**How PAES Works:**
- **(1+1)-ES Framework:**  
  One parent produces one child in each iteration.
  
- **Archive Comparison:**  
  - **If the child is dominated** by the archive, the parent is retained.
  - **If the child dominates** some members of the archive, those members are removed and the child is added.
  - **If the archive is not full**, the child is added, and a winner is chosen between the parent and the child.
  - **If the archive is full** and the child does not lie in the least crowded (highest count) hypercube, it may replace a random solution from that hypercube.
  
- **Winner Selection:**  
  The winner is determined based on which solution resides in a less crowded hypercube, promoting diversity.

> **Example:**  
> In a design scenario, if two similar solutions exist in a sparsely populated region, PAES may favor the one that better explores that region, ensuring the archive remains diverse.

---

## 18. Niching in PAES

**Niching Techniques** in PAES help in preserving a diverse set of solutions by:
- Dividing the objective space into hypercubes.
- Ensuring that solutions are maintained from each niche (or hypercube).

> **Analogy:**  
> Imagine a classroom where students are grouped into diverse teams to cover all aspects of a project. Niching ensures that no single team (or solution cluster) dominates the overall outcome.

---

## 19. Handling Constraints in MOEAs

Many real-world problems have constraints that can render some solutions infeasible. Handling these constraints is crucial for the success of MOEAs.

### Methods to Handle Constraints:

- **Penalty Function Approach:**  
  Modify each objective by adding a penalty term to account for constraint violations:
  \[
  F_m = f_m + R_m \cdot \Omega(\tilde{g})
  \]
  Here, \(R_m\) is a penalty parameter and \(\Omega(\tilde{g})\) quantifies the violation.
  
- **Explicit Procedures:**  
  Use specific strategies (such as those proposed by Jimenez or Ray-Tang-Seow) to treat infeasible solutions differently.
  
- **Modified Domination Concepts:**  
  Methods by Fonseca & Fleming or Deb et al. adjust the domination rule to incorporate constraint violations.

> **Insight:**  
> These techniques help the algorithm to gradually steer the search toward the feasible region while still considering solutions that are close to feasibility.

### Constrained Domination Principle

A solution \( i \) is said to **constrained-dominate** another solution \( j \) if at least one of the following is true:
1. **Feasibility Advantage:**  
   \( i \) is feasible while \( j \) is not.
2. **Less Constraint Violation:**  
   Both are infeasible, but \( i \) has a smaller overall constraint violation.
3. **Standard Domination:**  
   Both solutions are feasible and \( i \) dominates \( j \) in the usual Pareto sense.

> **Example:**  
> In bridge design, if one design slightly exceeds a non-critical constraint while another severely violates a safety constraint, the former is preferred under the constrained domination principle.

---

## 20. Constrained NSGA-II Simulation Results

When NSGA-II is extended to handle constraints:
- **Effective Constraint Management:**  
  The algorithm can differentiate between feasible and infeasible solutions using the constrained domination principle.
- **Maintaining Diversity:**  
  Despite the additional complexity, the algorithm still produces a well-spread Pareto front.

> **Observation:**  
> Simulation graphs typically show clusters of solutions where the best feasible candidates are clearly identified, demonstrating that NSGA-II effectively manages both constraint satisfaction and diversity.

---

## 21. Applications of MOEAs

MOEAs have been applied to a wide array of challenging problems, such as:
- **Spacecraft Trajectory Optimization:** Balancing fuel consumption, time, and safety.
- **Engineering Component Design:** Optimizing trade-offs among cost, performance, and durability.
- **Microwave Absorber Design:** Balancing efficiency with physical constraints.
- **Ground-Water Monitoring:** Optimizing coverage versus cost.
- **Extruder Screw Design:** Balancing manufacturing parameters.
- **Airline Scheduling:** Managing cost, timing, and customer satisfaction.
- **VLSI Circuit Design:** Optimizing power consumption, speed, and area.
- **Other Complex Systems:** Numerous engineering and real-world applications where multiple conflicting objectives must be balanced.

> **Practical Note:**  
> The versatility of MOEAs makes them invaluable in scenarios where the best compromise among competing objectives must be found.
